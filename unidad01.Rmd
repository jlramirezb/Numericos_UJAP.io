---
title: "Teoría de Errores"
author: "José Luis Ramírez"
date: "Octubre 2025"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: readable 
    css: css/estilos.css # Mantiene los estilos del navbar y body
    number_sections: true
---

# Motivación

* La gran mayoría de los modelos matemáticos que describen procesos físicos no pueden resolverse analíticamente.
* En una situación práctica, un problema matemático deriva de un fenómeno físico sobre el cual se han hecho algunas suposiciones para simplificarlo y poderlo representar matemáticamente.
* Una vez formulado el problema, deben diseñarse métodos numéricos para resolver el problema. La selección o construcción de los algoritmos apropiados cae propiamente dentro del terreno del Análisis Numérico.

---

# Teoría de Errores y Aproximación

El análisis numérico proporciona métodos computacionales para el estudio y solución de problemas matemáticos. Debido a que muchos cálculos son realizados en computadores digitales, es conveniente la discusión para la implementación de los métodos numéricos como programas de computador.

* Desafortunadamente los resultados son afectados por el uso de la **Aritmética de Precisión Finita**.
* Esperamos tener siempre expresiones verdaderas como $2 + 2 = 4$, $3^2 = 9$, $(\sqrt{5})^2 = 5$, pero en la aritmética de precisión finita $\sqrt{5}$ no tiene un solo número fijo y finito, que lo represente.

Los resultados numéricos están influenciados por muchos tipos de errores, los cuales pueden ser catalogados a grandes rasgos en tres tipos básicos:

* **Errores inherentes** que existen en los valores de los datos de entrada, ya sean causados por incertidumbre o por la naturaleza necesariamente aproximada de la representación.
* **Errores de discretización** (llamados también de truncamiento) que surgen al reemplazar procesos límites por su resultado antes de alcanzar tal límite.
* **Errores de redondeo** que se originan al utilizar una aritmética que involucra números con un número finito de dígitos.

## Errores Absolutos y Relativos.

Sea $x$ el valor exacto de un número real y $\tilde{x}$ el valor aproximado. Contemplando todos los posibles errores, la relación entre el resultado exacto y el aproximado es:
<div class="recuadro-gris">
$$
x=\tilde{x}+E
$$
</div>
Se define el error absoluto y se denota $E_a$ como la diferencia $x − \tilde{x}$, y se expresa siempre en valor absoluto.
<div class="recuadro-gris">
$$
E_a = |x - \tilde{x}|
$$
</div>

Al cociente entre el error absoluto $E_a$ y el valor real $x$ se le denomina error relativo y se denota por $E_r$. Se expresa también en valor absoluto, es decir:
<div class="recuadro-gris">
$$
E_r =\dfrac{|E_a|}{|x|} = \dfrac{|x - \tilde{x}|}{|x|}
$$
</div>

<div class="caja-ejemplo">

### Ejemplo 1

* Calculemos los errores absolutos y relativos para el valor $x= 1234.5678$, con aproximaciones a 4 dígitos $x_1=1234$ y $x_2=1235$ 
    -   $E_a = |x - x_1| = |1234.5678 - 1234| = 0.5678$, $E_r = \dfrac{|E_a|}{|x|} = \dfrac{0.5678}{1234.5678} \approx 5 \times 10^{-4}$.
    -   $E_a = |x - x_2| = |1234.5678 - 1235| = 0.4322$, $E_r = \dfrac{|E_a|}{|x|} = \dfrac{0.4322}{1234.5678} \approx 4 \times 10^{-4}$.
    
* Calculemos los errores absolutos y relativos para el valor $x= −0.00004599881234$, con aproximaciones a 4 dígitos $x_1=-0.00004599$ y $x_2=-0.00004600$ 
    -   $E_a = |x - x_1| = |−0.00004599881234 + 0.00004599| = 8.81234 \times 10^{−9}$, $E_r = \dfrac{|E_a|}{|x|} = \dfrac{8.81234×10^{−9}}{0.00004599881234} \approx 2 \times 10^{-4}$.
    -   $E_a = |x - x_2| = |−0.00004599881234 + 0.00004600| = 1.18766 \times 10^{−9}$, $E_r = \dfrac{|E_a|}{|x|} = \dfrac{1.18766 \times 10^{−9}}{0.00004599881234} \approx 2.5819 \times 10^{-4}$.

</div>

<u>Observaciones</u>:

* Mirando los ejemplos anteriores, vemos que los **errores absolutos** dependen de las magnitudes de los valores $x$: en el primer ejemplo los errores absolutos son de orden de $10^{−1}$; en cambio, en el segundo, son del orden de $10^{−9}$.

* En cambio, los **errores relativos** no se ven afectados por dichas magnitudes. Por dicho motivo, si queremos estudiar los errores sin tener en cuenta el orden de los valores $x$, hay que usar los **errores relativos**. Vemos que en los dos ejemplos los errores relativos son del orden de $10^{−4}$. ya que recordemos que las aproxi9maciones son a 4 **cifras decimales significativas**.

## Cifras Significativas.

Se dice que el número $\tilde{x}$ aproxima al número $x$ con $t$ dígitos (o cifras) significativas, si $t$ es el número entero más grande no negativo para el cual:
<div class="recuadro-gris">
$$E_r<0.5\times10^{-t} \Rightarrow \dfrac{|x - \tilde{x}|}{|x|} < 0.5 \times 10^{-t}$$
</div>

<div class="caja-ejemplo">
### Ejemplo 2
Sea $\tilde{x} = 3.1416$ una aproximación al valor $\pi$, y $x = 3.1415927$ una mejor aproximación.

``` {python, eval=TRUE, echo=TRUE}
import math
import string
from decimal import Decimal

def redondear(N,signif):
  """
      Dado un número real N y un número determinado de cifras significativas signif,
      nos da la aproximación de este número con signif cifras significativas.


        Parámetros:
        * N: número decimal
        * signif: número de digitos representativos

        Valor de retorno
        * número redondeado a signif número de cifras significativas

   """
  if int(N)==0:
    return float(round(Decimal(str(N)),signif))
  else:
    return float(round(Decimal(str(N)),signif-1-int(math.log(abs(N),10))))
  
def Err(num,dig):
    """
      Dado un número real y un número determinado de cifras significativas,
      nos da el error absoluto y relativo de dicho número.


        Parámetros:
        * num: número decimal
        * dig: número de cifras significativas

        Valor de retorno
        * Error absoluto
        * Error Relativo

    """
    err_abs=abs(num-redondear(num,dig))
    err_rel=err_abs/abs(redondear(num,dig))

    print("El error absoluto es {}".format(err_abs))
    print("El error relativo es {}".format(err_rel))

    return (err_abs, err_rel)

Err(3.1415927,5)
```
$$
\begin{align*}
E_a & = |x - \tilde{x}| = |3.1415927 - 3.1416| = 0.0000073 \\
E_r & = \dfrac{|E_a|}{|x|} = \dfrac{0.0000073}{3.1415927} \approx 0.232 \times 10^{-5}< 0.5 \times 10^{-5}
\end{align*}
$$
Luego, $\tilde{x}$ aproxima a $\pi$ con 5 cifras significativas.

</div>

## Aproximación de Números.

Sea $x = a_n\ldots a_0.b_1b_2\ldots \in \mathbb{R}$ (En cualquier base), para aproximar hasta el $t$-ésimo decimal:

* Por **truncamiento**
<div class="recuadro-gris">
$$
\tilde{x}_{trunc} = a_n\ldots a_0.b_1b_2\ldots b_t
$$
</div>
* Por **redondeo correcto**
<div class="recuadro-gris">
$$
\tilde{x}_{redon} = \begin{cases}
a_n\ldots a_0.b_1b_2\ldots b_t & \text{si } b_{t+1} < 5 \\
a_n\ldots a_0.b_1b_2\ldots b_t + \beta^{-t} & \text{si } b_{t+1} \geq 5
\end{cases}
$$
</div>

## Forma Normalizada de Números en Punto Flotante

Un número en punto flotante en base $\beta$ con precisión $t$ es un número que puede representarse en la forma:
<div class="recuadro-gris">
$$x = \sigma (0.d_1d_2\ldots d_t)_{\beta} \times \beta^e$$
</div>
donde:

* $\sigma$ es el signo del número ($+1$ o $-1$),
* $d_1d_2\ldots d_t$ son los dígitos en base $\beta$ (con $0 \leq d_i < \beta$ y $d_1 \neq 0$ para la forma normalizada),
* $e$ es el exponente entero, y es tal que $L \geq e \geq U$ para ciertos enteros $L$ y $U$.
* $t$ es la precisión (número de dígitos significativos).

Una de las características de todo conjunto de punto flotante $F$ es que es finito y tiene:
<div class="recuadro-gris">
$$
2(\beta - 1)\beta^{t-1}(U - L + 1) + 1
$$
</div>

números diferentes (incluyendo el cero), y donde los distintos de cero están en forma normalizada.

<div class="caja-ejemplo">
### Ejemplo 3
Sea el conjunto de punto flotante $F$ con parámetros $\beta = 2$(Binario), $t = 3$, $L = -2$, $U = 2$. Tal conjunto $F$ tiene
<div class="recuadro-gris">
$$2(2 - 1)2^{3 - 1}(2 - (-2) + 1) + 1 = 41$$
</div>
números diferentes (incluyendo el cero). La lista completa de números en $F$ es:
``` {python, eval=TRUE, echo=TRUE, message=FALSE}
import numpy as np
import matplotlib.pyplot as plt
def generar_punto_flotante(beta, t, L, U):
    numeros = set()
    for signo in [1, -1]:
        for exponente in range(L, U + 1):
            for d1 in range(1, beta):
                for d2 in range(beta):
                    for d3 in range(beta):
                        numero = signo * (d1 * beta**(-1) + d2 * beta**(-2) + d3 * beta**(-3)) * (beta ** exponente)
                        numeros.add(round(numero, 10))  # Redondear para evitar problemas de precisión
    numeros.add(0)  # Incluir el cero
    return sorted(numeros)

# Parámetros del sistema de punto flotante
beta = 2  # Base (binaria)
t = 3     # Dígitos de la mantisa
L = -2    # Exponente mínimo
U = 2     # Exponente máximo
punto_flotante = generar_punto_flotante(beta, t, L, U)
print("Números en el conjunto de punto flotante F:{}".format(punto_flotante))

# --- Visualización de la Recta Real y los Puntos ---
plt.figure(figsize=(12, 2)) # Ajusta el tamaño de la figura (ancho, alto)

# Dibuja la recta real (una línea horizontal)
plt.axhline(0, color='gray', linestyle='-', linewidth=1) 

# Dibuja los puntos generados sobre la recta 'o' para los marcadores, 'b' para el color azul, markersize para el tamaño
plt.plot(punto_flotante, np.zeros_like(punto_flotante), 'ob', markersize=5)
plt.plot(0, 0, 'go', markersize=7, label='Cero') # 'go' = green circle

# Etiquetas y Título
plt.title(f'Representación de Números de Punto Flotante (beta={beta}, t={t}, L={L}, U={U})')
plt.xlabel('Recta Real')

# Ajustes de los ejes para que los puntos sean más visibles
min_val = min(punto_flotante) - 0.5
max_val = max(punto_flotante) + 0.5
x_limits = plt.xlim(min_val, max_val) # Extiende ligeramente los límites del eje X
yticks = plt.yticks([]) # Oculta las marcas del eje Y, ya que solo es una recta horizontal

# Muestra una leyenda si es necesario
plt.legend()
plt.grid(True, linestyle=':', alpha=0.7)
plt.show()

```
</div>
* Hay un rango limitado para representar cantidades
  - Hay números grandes positivos y negativos que no pueden ser representados (overflow)
  - No pueden representarse números muy pequeños (underflow)
* Hay sólo un número finito de cantidades que puede ser representado dentro de un rango
  - El grado de precisión es limitado
  - Para aquellos que no pueden ser representados exactamente, la aproximación real se puede lograr: truncando o redondeando.
* El intervalo entre números aumenta tanto como los números crecen en magnitud
  - El error cuantificable más grande ocurrirá para aquellos valores que caigan justo debajo del límite superior de la primera serie de intervalos igualmente espaciados.

Vamos a ver cómo se almacena un número real en el ordenador en **formato binario** usando **64 bits**.

Sea $x$ un número real que suponemos en formato **binario**.

Escribimos $x$ de la forma siguiente:
<div class="recuadro-gris">
$$
x=(−1)^s 1.f\times2^{c−1023},
$$
</div>
donde

* $s$ indica el signo del número, indicado $s=0$ para los números positivos y $s=1$, para los negativos.
* $1.f$ es lo que se llama la mantisa donde $f$ es una secuencia de ceros y unos,
 es decir,
<div class="recuadro-gris">
$$
f= f_1f_2f_3\ldots f_n, \quad f_i \in \{0,1\}
$$
</div>
* $c \geq 1$ indica el exponente del número donde se le resta 1023 para poder representar números muy pequeños en valor absoluto. Escribimos $c−1023$ en binario como $c−1023=e_1e_2\ldots e_m$, con $e_i \in \{0,1\}$

Representamos $x$ por tres cajas: el signo $s$, la mantisa $f$ y el exponente $c−1023$ en binario:
<div class="recuadro-gris">
$$
|s| f_1f_2\ldots f_n| e_1e_2\ldots e_m|
$$
</div>

<div class="caja-ejemplo">
### Ejemplo 4: 
Representar el número $x=31.53173828125$ en formato de punto flotante de 64 bits.
$$
\begin{align*}
1. & \text{ Determinar el signo } s: \text{ Como } x > 0, \text{ entonces } s = 0. \\
2. & \text{ Convertir } x \text{ a binario: } \\
   & \quad \text{Parte entera: } 31_{10} = 11111_2. \\
   & \quad \text{Parte fraccionaria: } 0.53173828125_{10} = 0.10001000001_2. \\
   & \quad \text{Por lo tanto, } x \text{ en binario es aproximadamente } 11111.10001000001_2. \\
3. & \text{ Normalizar el número: } \\
   & \quad 11111.10001000001_2. = 1.111110001000001_2 \times 2^4. \\
4. & \text{ Determinar la mantisa } f: \\
   & \quad f = 111110001000001 \\
5. & \text{ Determinar el exponente } c - 1023: \\
   & \quad c = 4 + 1023 = 1027. \\
   & \quad \text{Convertir } 1027 \text{ a binario: } 1027_{10} = 10000000011_2. \\
6. & \text{ Representar el número en formato de 64 bits: } \\
   & \quad |0|111110001000001|10000000011|. \\
\end{align*}
$$
Como sólo tenemos 64 bits para representar el número, la cantidad de bits usados para su representación no puede superar 64

En caso que los superase, tendremos que considerar una aproximación del mismo.

En el ejemplo se usado el número siguiente de bits:

* signo: 1 bit,
* mantisa: 15 bits,
* exponente: 11 bits,

en total, 27 bits, por tanto, sí sería posible su representación exacta y no haría falta considerar una aproximación del mismo.
</div>  

<div class="caja-ejemplo">
### Ejemplo 5:
Hagamos la conversión contraria.

Imaginemos que nos dan el número siguiente:
$$
|1| 101101110011| 1111|.
$$
Vamos a ver a qué número $x$ corresponde.

El signo es negativo, por tanto $x<0$

La mantisa será:
$$
1.f=1+\frac{1}{2}+\frac{1}{2^3}+\frac{1}{2^4}+\frac{1}{2^6}+\frac{1}{2^7}+\frac{1}{2^8}+\frac{1}{2^{11}}+\frac{1}{2^{12}}=1.7155762.
$$
El exponente $c$ vale $1111_{2}−1023=1+2+2^2+2^3−1023=−1008$.

El número será:
$$
x=−1.7155762\times2^{−1008} \approx −6.25424\times10^{−304}.
$$
</div>
---

* La combinación aritmética usual $+, −, \times, \div$ de dos números de punto flotante no siempre produce un número
de punto flotante.
* Supongamos que $fl(x), fl(y) \in F$. Veamos, como ejemplo, que la suma usual $fl(x) + fl(y)$ no necesariamente será un
número en $F$. 
  - Sea el conjunto $F$ dado en el ejemplo: $fl(x) = 5/32 \in F$, $fl(y) = 48/32 \in F$, sin embargo $fl(x) + fl(y) = 5/32 + 48/32 = 53/32 \notin F$.
* Las operaciones aritméticas que realiza un computador no corresponden de forma exacta con las operaciones usuales. El estudio de lo que ocurre realmente es difı́cil de realiza y en todo caso depende de la máquina que se esté utilizand.o
* Denotando por $\oplus, \ominus, \otimes, \oslash$ las operaciones de suma, resta, multiplicación y división de la máquina. Se definen estas operaciones por:
<div class="recuadro-gris">
$$
\begin{align*}
x \oplus y & = fl(fl(x) + fl(y))\\
x \ominus y & = fl(fl(x) - fl(y))\\
x \otimes y & = fl(fl(x) \times fl(y))\\
x \oslash y & = fl(fl(x)/fl(y))
\end{align*}
$$
</div>

## Unidad de Precisión o Redondeo

* En la representación en punto flotante con $n$ dígitos en bas $\beta$ y exponente $e$, el error relativo en la representación de un número real $x$, $x \neq 0$ es estimado por:
<div class="recuadro-gris">
$$
\left|\dfrac{x-fl(x)}{x}\right| \leq \mu
$$
</div>
* donde $\mu$ se conoce como la unidad de precisión (o redondeo) de la máquina. El valor $\mu$ es una característica de la máquina, su sistema operativo y el modo de calcular (simple o doble precisión).
* Otra definición de $\mu \approx \epsilon$ (Epsilon de la máquina): $\epsilon$ es el número más pequeño positivo de la forma $\epsilon = 2^{-k}$ tal que:
<div class="recuadro-gris">
$$
1.0+\epsilon \neq 1.0 \quad \text{(en la máquina)}
$$
</div>

```{python}
# Definición de una función para calcular el épsilon de la máquina
def calcular_epsilon_maquina():
    """
    Calcula el épsilon de la máquina (el número más pequeño tal que 1 + eps > 1).
    """
    epsilon = 1.0
    
    # Mientras 1.0 + epsilon sea reconocido como igual a 1.0,
    # dividimos epsilon a la mitad.
    while 1.0 + epsilon > 1.0:
        epsilon /= 2.0
    
    # La última división hace que 1.0 + epsilon ya no sea > 1.0.
    # Por lo tanto, el verdadero épsilon es el valor anterior (el doble).
    return epsilon * 2.0

# Ejecutar la función y mostrar el resultado
epsilon_calculado = calcular_epsilon_maquina()

print("---")
print(f"Épsilon de la máquina (calculado): {epsilon_calculado}")
print(f"En notación científica: {epsilon_calculado:.2e}")
print("---")

# Comprobación de la definición:
# 1 + épsilon
print(f"Comprobación (1 + Épsilon): {1.0 + epsilon_calculado}")
# 1 + épsilon / 2 (debería ser igual a 1)
print(f"Comprobación (1 + Épsilon / 2): {1.0 + epsilon_calculado / 2.0}")
```

## Condicionamiento y Estabillidad

* Diremos que un proceso numérico, o una operación, es inestable cuando pequeños errores en los datos de entrada, o errores de redondeo en alguna de las etapas el proceso, producen errores grandes en los datos de salida.
* Diremos que un proceso numérico, es estable cuando no es inestable.
* Un mismo algoritmo puede ser estable para algunos datos iniciales e inestable para otros. Entonces se dice que el algoritmo es condicionalmente estable.

<div class="caja-ejemplo">
### Ejemplo 6
Nos planteamos calcular el valor $x_n=\frac{1}{3^n}$, donde $x_0=1$, $x_1=\frac{1}{3}$, $x_2=\frac{1}{9}$, y así sucesivamente.

Existe una fórmula recursiva para calcular $x_n$

$$
x_{n+1} = Ax_n + \left(\dfrac{1-3A}{9}\right)x_{n-1}
$$
donde $A$ es una constante fija.


**NumPy (Numerical Python)** es la librería esencial para el curso. Proporciona estructuras de datos eficientes (arrays) y funciones optimizadas para realizar operaciones de Álgebra Lineal.

* **Creación de un Array:**
    ```{python, eval=TRUE, echo=TRUE}
    # Bloque de código Python
    import numpy as np

    # Crear un array de 1 a 5
    a = np.array([1, 2, 3, 4, 5])
    print(a)
    print(a * 2) # Operación vectorial
    ```

### 3.2. Visualización con Matplotlib

Utilizaremos **Matplotlib** para graficar funciones, errores y visualizar resultados de nuestros métodos.

* **Gráfico de una Función Simple:**
    ```{python , eval=TRUE, echo=TRUE}
    # Bloque de código Python
    import matplotlib.pyplot as plt

    x = np.linspace(-np.pi, np.pi, 200)
    y = np.sin(x)

    plt.plot(x, y)
    plt.title("Función Seno")
    plt.show()
    ```

---

## 4. Repaso de Fundamentos Matemáticos

### 4.1. Concepto de Error y Precisión

Antes de codificar, debemos entender la fuente de nuestros errores:

* **Error de Truncamiento:** Error que resulta de usar una aproximación matemática (ej., truncar una serie infinita). [Enlace a una explicación detallada del Error de Truncamiento](recursos/error_truncamiento.html)
* **Error de Redondeo:** Error que resulta de la precisión limitada de la computadora (ej., usar números de punto flotante de 64 bits).

### 4.2. Convergencia y Dominio

Revisamos el concepto de **convergencia**. Muchos métodos numéricos son iterativos y solo son válidos si la secuencia de soluciones se aproxima a la respuesta verdadera. Recordamos la definición de límite:

$$
\lim_{n \to \infty} x_n = x_{verdadera}
$$

---

## 5. Tarea y Próxima Semana

* **Tarea:** Completar la instalación del entorno Python y verificar que los bloques de código en este módulo se ejecuten correctamente en tu sistema.
* **Próximo Módulo:** En el **Módulo 2**, comenzaremos con la resolución de ecuaciones no lineales (métodos de Bisección y Newton).

***

<small>Última revisión: `r format(Sys.Date(), "%d de %B, %Y")`</small>