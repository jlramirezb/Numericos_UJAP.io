---
title: "Interpolación Polinomial Y Ajuste de Curvas"
author: "José Luis Ramírez"
date: "Noviembre 2025"
output:
  html_document:
    self_contained: true
    mathjax: default
    pandoc_args: "--mathjax"
    toc: true
    toc_depth: 4
    toc_float: true
    theme: readable
    css: css/estilos.css
    number_sections: true
---

# Motivación

La ídea principal de este capítulo es aproximar una función $f$ cualquiera por un miembro de la familia más conocida y más sencilla de tratar: los polinomios.

Recordemos que un polinomio de grado $n$ tiene una expresión de la forma siguiente:

::: recuadro-gris
$$
P_n(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots + a_1x + a_0 = \sum_{i=0}^na_ix^i,
$$
:::

con $a_n \neq 0$ para que tenga grado $n$.

Los valores $a_i$, $i=0,1,\ldots,n$ se denominan coeficientes del polinomio $P_n$.

Cuanto “mejor” sea la función "$f$" a aproximar, es decir, cuanto más alto sea el valor de $k$ donde $f \in \mathcal C^k$, mejor control sobre el error cometido en la aproximación se tendrá, al menos teóricamente.

Al expresar la información mediante una fórmula polinómica, se facilitan operaciones como el cálculo de valores intermedios, la interpolación y la predicción de comportamientos futuros, derivación e integración.

Se supone por ejemplo que se tiene una tabla que relaciona la viscosidad dinámica del agua con la temperatura

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)

datos <- data.frame(
  "T ºC" = c(0, 5, 10, 20),
  "$\\mu_o$" = c(1.787, 1.519, 1.307, 1.002),
  check.names = FALSE
)

kable(datos, align = "c", escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width = FALSE, 
                position = "center")
```

¿Cómo estimar la viscosidad a una temperatura de 7.5º C? Una opción es encontrar un polinomio que pase por los puntos de la tabla y estimar el valor de 7.5 con él.

En este capítulo se presentarán dos técnicas para aproximar una función mediante un polinomio: la interpolación, que ajusta el polinomio pasando exactamente por los datos, y la aproximación por mínimos cuadrados, que busca minimizar el error global cuando no es posible (o deseable) que el polinomio pase por todos los puntos.

```{python, echo=FALSE, message=FALSE, warning=FALSE}
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import lagrange

# Datos de ejemplo (con algo de ruido para que se note la diferencia)
x = np.array([0, 1, 2, 3, 4, 5])
y = np.array([2.1, 2.9, 4.2, 5.1, 3.8, 6.5])

# 1. Interpolación (Polinomio de Lagrange)
# Pasa exactamente por todos los puntos
poly_interp = lagrange(x, y)
x_dense = np.linspace(min(x), max(x), 100)
y_interp = poly_interp(x_dense)

# 2. Mínimos Cuadrados (Ajuste lineal - grado 1)
# Minimiza el error global, no necesariamente pasa por los puntos
coeffs_ls = np.polyfit(x, y, 1)
poly_ls = np.poly1d(coeffs_ls)
y_ls = poly_ls(x_dense)

# Gráfica
plt.figure(figsize=(10, 6))
plt.scatter(x, y, color='red', label='Datos originales', zorder=5)
plt.plot(x_dense, y_interp, label=f'Interpolación (Grado {len(x)-1})', linestyle='--')
plt.plot(x_dense, y_ls, label='Mínimos Cuadrados (Grado 1)', color='green')

plt.title('Diferencia entre Interpolación y Mínimos Cuadrados')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

## Algoritmo de Horner

Si el polinomio $P_n(x)$ se escribe en la forma:

::: recuadro-gris
$$
P_n(x)=a_0+a_1x+a_2x^2+\cdots+a_nx^n
$$
:::

Se necesitan menos operaciones para evaluarlo en un punto $x_0$ si se escribe:

::: recuadro-gris
$$
P_n(x) = a_0 + x(a_1 + x(\cdots (a_{n-2} + x(a_{n-1} + x a_n)) \cdots ))
$$
:::

El algoritmo de Horner es un algoritmo que permite evaluar un polinomio en un punto $x_0$ de forma eficiente, para ello se define

::: recuadro-gris
\begin{align*}
b_n & = a_n\\
b_{k} & = a_{k} + x_0 b_{k+1}, \forall k \in \mathbb{N}, 0 \leq k < n\\
P_n(x_0) & = b_0
\end{align*}

Además, si se llama
$$
Q_{n-1}(x) = b_nx^{n-1} + b_{n-1}x^{n-2} + b_{n-2}x^{n-2} + \cdots + b_2x + b_1
$$

Se tiene que $P_n(x) = (x-x_0)Q_{n-1}(x)+b_0$ y por lo tanto $P'_n(x_0)=Q_{n-1}(x_0)$
:::

::: cuadro-alg
**FUNCIÓN HORNER(a, x0)**

    # ENTRADA:
    #   a:      Una lista o array de coeficientes del polinomio, donde a[i] es el coeficiente de x^i.
    #           Es decir, a = [a_0, a_1, ..., a_n].
    #   x0:     El punto en el que se desea evaluar el polinomio.

    # SALIDA:
    #   P_n(x0): El valor del polinomio evaluado en x0.

    # Función auxiliar recursiva para calcular b_k
    FUNCIÓN _HORNER_RECURSIVO(coefs, x_val, k)
        # Caso base: Si k es el índice del coeficiente de mayor grado (a_n),
        # entonces b_n = a_n.
        SI k == longitud(coefs) - 1 ENTONCES
            RETORNAR coefs[k]
        FIN SI

        # Paso recursivo: b_k = a_k + x0 * b_{k+1}
        RETORNAR coefs[k] + x_val * _HORNER_RECURSIVO(coefs, x_val, k + 1)
    FIN FUNCIÓN

    # La evaluación del polinomio P_n(x0) es b_0.
    # Iniciamos la recursión para calcular b_0.
    RETORNAR _HORNER_RECURSIVO(a, x0, 0)
:::

¿Por qué es Importante el Algoritmo de Horner?

* **Eficiencia**: Es más eficiente que calcular las potencias de $x_0$ y multiplicar por los coeficientes de forma individual (se usa menos memoria y tiempo de cómputo).

* **Estabilidad**: Reduce errores de redondeo en cálculos numéricos.

* **Derivadas**: Permite obtener información sobre la derivada del polinomio en el mismo punto.

* **División Sintética**: Está relacionado con el método de divisíon sintética para polinomios, lo que lo hace muy útil en el campo del álgebra y el análisis numérico.

::: caja-ejemplo
#### Ejemplo 1

Tenemos el polinomio:
$$
P_3(x) = 2x^3 - 3x^2 + 4x - 1
$$
Y queremos evaluarlo en $x_0 = 2$ y también calcular $P'_3(2)$.

**Solución**

Para el polinomio $P_3(x) = 2x^3 - 3x^2 + 4x - 1$ y $x_0 = 2$.

Los coeficientes del polinomio son $a = [-1, 4, -3, 2]$, donde $a_0 = -1$, $a_1 = 4$, $a_2 = -3$ y $a_3 = 2$.

**Paso 1: Evaluar $P_3(2)$ usando el Algoritmo de Horner.**

Aplicamos la fórmula $b_k = a_k + x_0 b_{k+1}$ de arriba hacia abajo (desde $k=n$ hasta $k=0$):

1.  $b_3 = a_3 = 2$
2.  $b_2 = a_2 + x_0 b_3 = -3 + (2)(2) = -3 + 4 = 1$
3.  $b_1 = a_1 + x_0 b_2 = 4 + (2)(1) = 4 + 2 = 6$
4.  $b_0 = a_0 + x_0 b_1 = -1 + (2)(6) = -1 + 12 = 11$

Por lo tanto, $P_3(2) = b_0 = 11$.

**Paso 2: Evaluar $P'_3(2)$ usando el Algoritmo de Horner.**

Sabemos que $P'_n(x_0) = Q_{n-1}(x_0)$, donde $Q_{n-1}(x) = b_nx^{n-1} + b_{n-1}x^{n-2} + \cdots + b_2x + b_1$.
En nuestro caso, $Q_2(x) = b_3x^2 + b_2x + b_1 = 2x^2 + 1x + 6$.

Los coeficientes para $Q_2(x)$ son $c = [6, 1, 2]$, donde $c_0 = 6$, $c_1 = 1$ y $c_2 = 2$.
Aplicamos el Algoritmo de Horner a $Q_2(x)$ en $x_0 = 2$:

1.  $d_2 = c_2 = 2$
2.  $d_1 = c_1 + x_0 d_2 = 1 + (2)(2) = 1 + 4 = 5$
3.  $d_0 = c_0 + x_0 d_1 = 6 + (2)(5) = 6 + 10 = 16$

Por lo tanto, $P'_3(2) = Q_2(2) = d_0 = 16$.

**Verificación (opcional):**

Podemos verificar los resultados calculando el polinomio y su derivada de forma directa:

$P_3(x) = 2x^3 - 3x^2 + 4x - 1$
$P_3(2) = 2(2)^3 - 3(2)^2 + 4(2) - 1 = 2(8) - 3(4) + 8 - 1 = 16 - 12 + 8 - 1 = 4 + 8 - 1 = 12 - 1 = 11$.

$P'_3(x) = 6x^2 - 6x + 4$
$P'_3(2) = 6(2)^2 - 6(2) + 4 = 6(4) - 12 + 4 = 24 - 12 + 4 = 12 + 4 = 16$.

Los resultados coinciden.

```{python, eval=TRUE}
# Implementación del algoritmo de Horner en Python para verificar
import numpy as np

def horner_eval(a, x0):
    """
    Evalúa un polinomio en un punto x0 usando el algoritmo de Horner.
    a: lista de coeficientes [a_0, a_1, ..., a_n]
    x0: punto de evaluación
    """
    n = len(a) - 1
    b = [0] * (n + 1)
    b[n] = a[n]
    for k in range(n - 1, -1, -1):
        b[k] = a[k] + x0 * b[k+1]
    return b[0], b # Retorna P(x0) y los coeficientes b_k

# Coeficientes del polinomio p_3(x) = 2x^3 - 3x^2 + 4x - 1
# a = [a_0, a_1, a_2, a_3]
a = [-1, 4, -3, 2]
x0 = 2

# Evaluar p_3(2)
p_x0, b_coeffs = horner_eval(a, x0)
print(f"p_3({x0}) = {p_x0}") # Debería ser 11

# Los coeficientes b_k son [b_0, b_1, b_2, b_3]
# Para la derivada, usamos [b_1, b_2, b_3] como los coeficientes del polinomio Q(x)
# Q(x) = b_3*x^2 + b_2*x + b_1
# Los coeficientes para Q(x) son [b_1, b_2, b_3]
q_coeffs = b_coeffs[1:] # [6, 1, 2]

# Evaluar Q(2) para obtener p'_3(2)
p_prime_x0, _ = horner_eval(q_coeffs, x0)
print(f"p'_3({x0}) = {p_prime_x0}") # Debería ser 16
```
:::

# Interpolación y aproximación numérica

Para justificar la aproximación de una función $f$ por polinomios veamos el **Teorema de Weierstrass** que dice básicamente que cualquier función continua puede aproximarse por un polinomio con un error tan pequeño como se quiera:

::: caja-lema
**Teorema de Weierstrass**.

Sea $f \in \mathcal{C}^0[a,b]$ una función continua en un intervalo $[a,b]$. Entonces dado un valor $\epsilon>0$, existe un polinomio $P_n(x)$ de un grado determinado $n$ tal que:

::: recuadro-gris
$$
|f(x)−P_n(x)|<\epsilon,
$$
:::

para todo valor $x \in [a,b]$.
:::

El problema que intentamos resolver es el siguiente:

**Problema**: Dados $n$ valores $(x_0,y_0), (x_1,y_1), \dots, (x_n,y_n)$, se desea hallar polinomio $P_n$ de grado mínimo tal que $P_n(x_i)=y_i,\, i=0,\ldots,n$.

Es decir, dados $n+1$ puntos en el plano, hallar un polinomio de grado mínimo, (más adelante veremos que dicho grado es $n$) tal que $P_n(x_i)=y_i,\, i=0,\ldots,n$.

**Observaciones**:

* Si los puntos son parte de la gráfica de una función $f$, entonces $y_i=f(x_i)$ y las condiciones que debe verificar el polinomio $P_n(x)$ son $P_n(x_i)=f(x_i),\, i=0,\ldots,n$.

* Se tiene en total $n+1$ condiciones, por tanto, el número de incógnitas debe ser $n+1$. Pensemos que un polinomio de grado $n$ tiene en total $n+1$ coeficientes.

Sea pues $P_n(x)=a_0+a_1x+\cdots+a_nx^n$ el polinomio a hallar.

Las condiciones $P_n(x_i)=y_i$ serían las siguientes en función de los coeficientes $a_i$, $i=0,\ldots,n$:

$$
a_0+a_1x_i+\cdots+a_nx_i^n=y_i,\quad i=0,\ldots,n.
$$

Los coeficientes $a_i$ deben verificar el siguiente **sistema de ecuaciones lineales**:

::: recuadro-gris
$$
\begin{cases}
a_0+a_1x_0+\cdots+a_nx_0^n=y_0,\\
a_0+a_1x_1+\cdots+a_nx_1^n=y_1,\\
\vdots\\
a_0+a_1x_n+\cdots+a_nx_n^n=y_n.
\end{cases}
$$
:::

Este sistema lineal tiene solución única y tiene por determinante del sistema el siguiente:

::: recuadro-gris
$$
D=\begin{vmatrix}
1 & x_0 & x_0^2 & \cdots & x_0^n\\
1 & x_1 & x_1^2 & \cdots & x_1^n\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
1 & x_n & x_n^2 & \cdots & x_n^n
\end{vmatrix}
$$
:::

El determinante anterior se llama **determinante de Vandermonde** y su valor es:
$$
\prod_{0\leq i<j\leq n}(x_i-x_j).
$$

Por tanto, si $x_i\neq x_j$ para $i\neq j$, el determinante del sistema no será cero y tendremos solución única para nuestro problema.

En resumen, tenemos el teorema siguiente:

::: caja-lema
**Teorema**.

Sean $(x_0,y_0),(x_1,y_1),\ldots,(x_n,y_n)$, $n$ valores con $x_i\neq x_j$ para $i\neq j$ (es decir, las abscisas son todas diferentes). Entonces existe un único polinomio $P_n(x)$ de grado $n$
 tal que $P_n(x_i)=y_i$, $i=0,\ldots,n$.
:::

## Interpolación de Lagrange

El método de Lagrange para interpolación polinomial resulta de resolver el sistema de Vandermonde para obtener los coeficientes pero lo hace de una forma más sencilla y sistemática.

Se construye el polinomio interpolador de forma explícita en función de unos polinomios especiales denominados **polinomios interpoladores de Lagrange**:

::: caja-lema
**Polinomios de Lagrange**.

Sean $x_0,\ldots,x_n$, $n+1$ nodos donde suponemos que $x_i \neq x_j$, para $i\neq j$. Se define el polinomio de Lagrange $L_{k}(x)$ de grado $n$ asociado al nodo $x_k$ de la forma siguiente:

::: recuadro-gris
\begin{align*}
L_{k}(x)& = \dfrac{(x-x_0)(x-x_1)\cdots(x-x_{k-1})(x-x_{k+1})\cdots(x-x_n)}{(x_k-x_0)(x_k-x_1)\cdots(x_k-x_{k-1})(x_k-x_{k+1})\cdots(x_k-x_n)}\\
& =\prod_{\substack{0\leq i\leq n\\i\neq k}}\frac{x-x_i}{x_k-x_i}
\end{align*}
:::
:::

Los polinomios de Lagrange verifican la proposición siguiente:

Sean $x_0,\ldots,x_n$, $n+1$ nodos donde suponemos que $x_i \neq x_j$, para $i\neq j$. Sean $L_{k}(x)$ el polinomio de Lagrange de grado menor o igual a $n$ asociado al nodo $x_k$. Entonces dicho polinomio verifica que:

::: recuadro-gris
$$
L_{k}(x_k)=1\quad\text{y}\quad L_{k}(x_i)=0\quad\text{para}\quad i\neq k.
$$
:::

::: caja-ejemplo
#### Ejemplo 2.

Consideremos los nodos $x_0=0,\, x_1=1,\, x_2=3,\, x_3=5$.

Los polinomios de Lagrange asociados a los nodos anteriores son los siguientes:

::: recuadro-gris
\begin{align*}
L_0(x) & = \dfrac{(x-1)(x-3)(x-5)}{(0-1)(0-3)(0-5)} = \dfrac{1}{-15}(x^3-9x^2+23x-15)\\
L_1(x) & = \dfrac{(x-0)(x-3)(x-5)}{(1-0)(1-3)(1-5)} = \dfrac{1}{8}(x^3-8x^2+15x)\\
L_2(x) & = \dfrac{(x-0)(x-1)(x-5)}{(3-0)(3-1)(3-5)} = \dfrac{1}{-12}(x^3-6x^2+5x)\\
L_3(x) & = \dfrac{(x-0)(x-1)(x-3)}{(5-0)(5-1)(5-3)} = \dfrac{1}{40}(x^3-4x^2+3x) \\
\end{align*}
:::

```{python, echo=FALSE}
import numpy as np
import matplotlib.pyplot as plt

# Nodos x_k
x_nodes = np.array([0, 1, 3, 5])

# Definición de los polinomios de Lagrange
def L0(x):
    return (1 / -15) * (x**3 - 9*x**2 + 23*x - 15)

def L1(x):
    return (1 / 8) * (x**3 - 8*x**2 + 15*x)

def L2(x):
    return (1 / -12) * (x**3 - 6*x**2 + 5*x)

def L3(x):
    return (1 / 40) * (x**3 - 4*x**2 + 3*x)

# Rango de x para graficar
x_vals = np.linspace(-1, 6, 400)

plt.figure(figsize=(10, 6));

# Graficar L0(x)
plt.plot(x_vals, L0(x_vals), label='$L_0(x)$', color='red');
plt.plot(x_nodes[0], L0(x_nodes[0]), 'ro', markersize=8, label='$(x_0, L_0(x_0))$');
# (0, 1)

# Graficar L1(x)
plt.plot(x_vals, L1(x_vals), label='$L_1(x)$', color='green');
plt.plot(x_nodes[1], L1(x_nodes[1]), 'go', markersize=8, label='$(x_1, L_1(x_1))$');
# (1, 1)

# Graficar L2(x)
plt.plot(x_vals, L2(x_vals), label='$L_2(x)$', color='blue');
plt.plot(x_nodes[2], L2(x_nodes[2]), 'bo', markersize=8, label='$(x_2, L_2(x_2))$');
# (3, 1)

# Graficar L3(x)
plt.plot(x_vals, L3(x_vals), label='$L_3(x)$', color='purple');
plt.plot(x_nodes[3], L3(x_nodes[3]), marker='o', color='purple', markersize=8, label='$(x_3, L_3(x_3))$');
# (5, 1)

# Añadir puntos (x_i, 0) para todos los polinomios
for i, x_node in enumerate(x_nodes):
    if i != 0: # For L0, x0 is (x0,1)
        plt.plot(x_node, L0(x_node), 'rx', markersize=6);
    if i != 1: # For L1, x1 is (x1,1)
        plt.plot(x_node, L1(x_node), 'gx', markersize=6);
    if i != 2: # For L2, x2 is (x2,1)
        plt.plot(x_node, L2(x_node), 'bx', markersize=6);
    if i != 3: # For L3, x3 is (x3,1)
        plt.plot(x_node, L3(x_node), marker='x', color='purple', markersize=6);


plt.axhline(0, color='gray', linestyle='-', linewidth=2);
plt.axhline(1, color='gray', linestyle='--', linewidth=1.5);
plt.axvline(0, color='gray', linestyle='-', linewidth=2);
plt.xlabel('x');
plt.ylabel('$L_k(x)$');
plt.title('Polinomios de Lagrange $L_k(x)$ y puntos $(x_k, L_k(x_k))$');
plt.legend();
plt.grid(True)
plt.show()
```
:::

El Teorema siguiente nos dice cómo calcular el polinomio interpolador a partir de los polinomios de Lagrange:

::: caja-lema
**Teorema**.

Sean $(x_0,y_0),(x_1,y_1),\ldots,(x_n,y_n)$, $n+1$ puntos con $x_i\neq x_j$ para $i\neq j$, y con $y_i=f(x_i)$ para $i=0,\ldots,n$. Entonces el polinomio interpolador $P_n(x)$ que pasa por dichos puntos se puede escribir de la siguiente forma:

::: recuadro-gris
\begin{align*}
P_n(x)&=y_0L_0(x)+y_1L_1(x)+\cdots+y_nL_n(x)\\
&=\sum_{k=0}^{n}y_kL_k(x).
\end{align*}
:::
donde $L_k(x)$ es el polinomio de Lagrange correspondiente al nodo $x_k$, $k=0,\ldots,n$.
:::

::: caja-ejemplo
#### Ejemplo 3.

Calculemos el polinomio interpolador en los nodos $x_0=0$, $x_1=1$, $x_2=3$, $x_3=5$ para la función $f(x)=x\cdot\sin\left(\frac{\pi}{2}\cdot x\right)$.

Los puntos de interpolación serían $(0,0)$, $(1,1)$, $(3,-3)$, $(5,5)$.

El polinomio interpolador $P_3(x)$ que pasa por dichos puntos se puede escribir de la siguiente forma:

::: recuadro-gris
\begin{align*}
P_3(x)&=y_0L_0(x)+y_1L_1(x)+y_2L_2(x)+y_3L_3(x)\\
&=0\cdot L_0(x)+1\cdot L_1(x)-3\cdot L_2(x)+5\cdot L_3(x)\\
&=1\cdot\left(\frac{1}{8}(x^3-8x^2+15x)\right)-3\cdot\left(\frac{1}{-12}(x^3-6x^2+5x)\right)+5\cdot\left(\frac{1}{40}(x^3-4x^2+3x)\right)\\
&= 0.5x^3-3x^2+3.5x
\end{align*}
:::

```{python, echo=FALSE}
import numpy as np
import matplotlib.pyplot as plt

# Definir la función f(x)
def f(x):
    return x * np.sin(np.pi/2 * x)

# Definir el polinomio interpolador P3(x)
def P3(x):
    return 0.5 * x**3 - 3 * x**2 + 3.5 * x

# Nodos de interpolación
x_nodes = np.array([0, 1, 3, 5])
y_nodes = np.array([0, 1, -3, 5]) # y_i = f(x_i)

# Rango de x para graficar
x_vals = np.linspace(-1, 6, 400)

plt.figure(figsize=(10, 6));

# Graficar la función f(x)
plt.plot(x_vals, f(x_vals), label='$f(x) = x \\cdot \\sin(\\frac{\\pi}{2}x)$', color='blue');

# Graficar el polinomio interpolador P3(x)
plt.plot(x_vals, P3(x_vals), label='$P_3(x) = 0.5x^3 - 3x^2 + 3.5x$', color='red');

# Graficar los nodos interpolantes
plt.plot(x_nodes, y_nodes, 'ko', markersize=8, label='Nodos de interpolación $(x_i, y_i)$');

plt.xlabel('x');
plt.ylabel('y');
plt.title('Función $f(x)$ y Polinomio Interpolador $P_3(x)$');
plt.legend();
plt.grid(True)
plt.axhline(0, color='black', linestyle='-', linewidth=1.5);
plt.axvline(0, color='black', linestyle='-', linewidth=1.5);
plt.xlim(-0.5, 6);
plt.ylim(-4, 6);
plt.show()
```
:::

### Error de interpolación.

Interpolar una función $f$ en unos nodos determinados puede interpretarse como una manera de aproximar la función $f$ en un entorno de los nodos, es decir, en un dominio que esté relativamente cerca de dichos nodos.

Es fundamental estimar de alguna manera el error cometido en un valor cualquiera cuando se intenta aproximar una función. El Teorema siguiente nos da una expresión del error cometido cuando aproximamos una función $f$ por un polinomio interpolador:

::: caja-lema
**Teorema**.

Sea $f \in C^{n+1}[a, b]$ y $P_n(x)$ el polinomio de interpolación en los $n + 1$ puntos
distintos $x_0 = a, x_1, \ldots, x_n = b$, entonces para cada $x \in [a, b]$ existe
$\xi(x) \in I[x_0, x_1, \ldots, x_n, x]$ (el intervalo cerrado más pequeño que contiene
$x_0, x_1, \ldots, x_n, x$) tal que

::: recuadro-gris
\begin{align*}
E(x)&=f(x)-P_n(x)\\
&=\dfrac{f^{(n+1)}(\xi(x))}{(n+1)!}\prod_{k=0}^{n}(x-x_k)
\end{align*}
:::

donde $\xi(x)$ es un punto en el intervalo $[a,b]$.
:::

::: caja-ejemplo
#### Ejemplo 4.

La expresión del error cometido al aproximar la función $f(x)=x\cdot\sin\left(\frac{\pi}{2}x\right)$ en el **ejemplo 3** es:

::: recuadro-gris
\begin{align*}
E(x)&=f(x)-P_3(x)\\
&=\dfrac{f^{(4)}(\xi(x))}{4!}\cdot x\cdot(x-1)\cdot(x-3)\cdot(x-5)
\end{align*}
:::

Hallando $f^{(4)}(x)$:

::: recuadro-gris
\begin{align*}
f'(x) & = \sin\left(\frac{\pi}{2}x\right)+\frac{\pi}{2}x\cdot\cos\left(\frac{\pi}{2}x\right)\\
f''(x)& = \pi\cos\left(\frac{\pi}{2}x\right)-\frac{\pi^2}{4}x\cdot\sin\left(\frac{\pi}{2}x\right)\\
f'''(x)& = -\frac{3\pi^2}{4}\sin\left(\frac{\pi}{2}x\right)-\frac{\pi^3}{8}x\cdot\cos\left(\frac{\pi}{2}x\right)\\
f^{(4)}(x)& = -\frac{\pi^3}{2}\cos\left(\frac{\pi}{2}x\right)+\frac{\pi^4}{16}x\cdot\sin\left(\frac{\pi}{2}x\right)
\end{align*}
:::

La expresión del error es:

::: recuadro-gris
$$
f(x) - P_3(x) = \dfrac{\pi^3}{384} \left[ -8\cos\left(\dfrac{\pi \xi(x)}{2}\right) + \pi \xi(x) \sin\left(\dfrac{\pi \xi(x)}{2}\right) \right] x(x-1)(x-3)(x-5)
$$
:::

Imaginemos que queremos acotar el error cometido $|f(x)−P_3(x)|$ para todo valor de $x$ en el intervalo $[0,5]$. Entonces, tendremos:

::: recuadro-gris
$$
|E(x)|=|f(x) - P_3(x)| \leq \dfrac{\pi^3(8+5\pi)}{384} \cdot \max_{x \in [0,5]} |x(x-1)(x-3)(x-5)|
$$
:::

Ahora para hallar $\max_{x \in [0,5]} |x(x-1)(x-3)(x-5)|$ debemos hallar el valor máximo de la función $h(x)=x(x-1)(x-3)(x-5) = x^4 - 9x^3+23x^2-15x$ en el intervalo $[0,5]$, el cual se encuentra dentro del intervalo $(0,5)$, ya que $h(0)=0$ y $h(5)=0$.

$$
h'(x) = 4x^3 - 27x^2 + 46x - 15
$$

El siguiente paso es resolver la ecuación $h'(x)=0$, para resolver esta ecuación, se puede usar un método numérico de los vistos en la unidad III. Eligiendo adecuadamente los valores iniciales se llega a los siguientes ceros:

$$
\begin{align*}
x_1 &= 0.4257862 \quad |h(x_1)| = 2.878898\\
x_2 &= 2.0704646 \quad |h(x_2)| = 6.035382\\
x_3 &= 4.2537492 \quad |h(x_3)| = 12.949453
\end{align*}
$$

Por lo tanto, el valor máximo de $|h(x)|$ en el intervalo $[0,5]$ es $12.949453$.

Por lo tanto, el valor máximo de $|E(x)|$ en el intervalo $[0,5]$ es $\dfrac{\pi^3(8+5\pi)}{384} \cdot 12.949453 \approx 24.7892891.$.

La cota del error obtenida es una cota “teórica”. Si se representa el valor absoluto del error exacto: $|E(x)| = |f(x) − P_3(x)|$ se obtiene la siguiente figura:

```{python, echo=FALSE}
import numpy as np
import matplotlib.pyplot as plt

# Definir la función f(x) (reutilizada del ejemplo 3)
def f(x):
    return x * np.sin(np.pi/2 * x)

# Definir el polinomio interpolador P3(x) (reutilizado del ejemplo 3)
def P3(x):
    return 0.5 * x**3 - 3 * x**2 + 3.5 * x

# Rango de x para graficar (reutilizado del ejemplo 3)
x_vals = np.linspace(0, 5, 400)

# Calcular el error absoluto
error_abs = np.abs(f(x_vals) - P3(x_vals))

plt.figure(figsize=(10, 6));

# Graficar el error absoluto
plt.plot(x_vals, error_abs, label='$|f(x) - P_3(x)|$', color='orange');

# Nodos de interpolación (reutilizados del ejemplo 3)
x_nodes = np.array([0, 1, 3, 5])
# En los nodos, el error es cero por definición
plt.plot(x_nodes, np.zeros_like(x_nodes), 'ko', markersize=8, label='Nodos de interpolación ($x_i$, 0)');

plt.xlabel('x');
plt.ylabel('$|E(x)|$');
plt.title('Diferencia absoluta entre $f(x)$ y $P_3(x)$');
plt.legend();
plt.grid(True)
plt.axhline(0, color='black', linestyle='-', linewidth=1.5);
plt.axvline(0, color='black', linestyle='-', linewidth=1.5);
plt.xlim(-0.5, 5.5);
plt.ylim(-0.5, 4); 
# Ajustar el límite y para visualizar mejor el error
plt.show()
```

Si se hubiese acotado la derivada $f^{(4)}(x)$ hallando el valor máximo dentro del intervalo $[0,5]$ se hubiese obtenido una cota más fina.

:::

**Desventajas del método de Lagrange**

* El polinomio no viene expandido.

* La interpolación para otro valor de $x$ necesita la misma cantidad de cálculos adicionales, ya que no se pueden utilizar partes de la aplicación previa.

* La incorporación de un nuevo nodo obliga a rehacer todos los cálculos.

* La evaluación del error no es fácil.

## Interpolación Iterada

* A veces no es necesario obtener la forma explícita del polinomio interpolador y basta con obtener su valor numérico en un punto dado.

* Además en este caso se desea poder aumentar el orden del polinomio interpolador a voluntad y parar cuando el error sea suficientemente pequeño.

* Para estos propósitos la interpolación iterada está especialmente indicada.

::: caja-lema
**Definición**.

Sea $f$ una funcíon definida en $x_0, \ldots, x_n$ y supongamos $m_0, \ldots, m_k$ sean $k + 1$ enteros distintos con $0 \leq m_i \leq n$ para cada $i = 0, \ldots, k$. El polinomio de Lagrange de grado menor o igual a $k$ que coincide con $f$ en $x_{m_0}, \ldots, x_{m_k}$ se denota $P_{m_0,\ldots,m_k}$.
::: 

::: caja-ejemplo
#### Ejemplo 5.

Sea $f(x) = x^3$, $x_0 = 1$, $x_1 = 2$, $x_2 = 3$, $x_3 = 4$, $x_4 = 6$, calcule $P_{0,3,4}(x)$ y $P_{1,2,4}(x)$.

\begin{align*}
P_{0,3,4}(x) &= L_0(x)f(x_0)+L_3(x)f(x_3)+L_4(x)f(x_4)\\
& =\dfrac{(x-4)(x-6)}{(1-4)(1-6)}\cdot 1^3+\dfrac{(x-1)(x-6)}{(4-1)(4-6)}\cdot 4^3+\dfrac{(x-1)(x-4)}{(6-1)(6-4)}\cdot 6^3\\
& = 11x^2-34x+24
\end{align*}

\begin{align*}
P_{1,2,4}(x) &= L_1(x)f(x_1)+L_2(x)f(x_2)+L_4(x)f(x_4)\\
& =\dfrac{(x-3)(x-6)}{(2-3)(2-6)}\cdot 2^3+\dfrac{(x-2)(x-6)}{(3-2)(3-6)}\cdot 3^3+\dfrac{(x-2)(x-3)}{(6-2)(6-3)}\cdot 6^3\\
& = 10x^2-27x+18
\end{align*}
::: 


------------------------------------------------------------------------
  
<small>Última revisión: `r format(Sys.Date(), "%d de %B, %Y")`</small>
